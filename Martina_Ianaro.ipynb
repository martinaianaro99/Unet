{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exam July 29\n",
        "\n",
        "Martina Ianaro. ID: 973377"
      ],
      "metadata": {
        "id": "XuYBHe9-lh2z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaBRQCrjUYM7"
      },
      "source": [
        "# Task\n",
        "\n",
        "The purpose of the project is to separate an image obtained as a sum of a two images into its components.\n",
        "\n",
        "The two images img1 and img2 summed together come from different dataset: mnist and fashion_mnist, respectively.\n",
        "\n",
        "No preprocessing is allowed. The network takes in input the sum img1+img2 and returns the predicted components hat_img1 and hat_img2.\n",
        "\n",
        "The metric used to evaluate the project is the mean squared error between predicted and ground truth images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlQLYQMNUVxj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from tensorflow import keras as ks\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Creation\n",
        "Here we load the two datasets, mnist and fashion mnist (both in grayscale).\n",
        "\n",
        "For simplicity, the samples are padded to dimension (32,32)"
      ],
      "metadata": {
        "id": "jt0uipoWlrRy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB7BI586Uiqq",
        "outputId": "0c6f9bb8-e2b6-4835-e991-29daec96a7e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 32, 32)\n"
          ]
        }
      ],
      "source": [
        "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n",
        "print(np.shape(mnist_x_train))\n",
        "(fashion_mnist_x_train, fashion_mnist_y_train), (fashion_mnist_x_test, fashion_mnist_y_test) = fashion_mnist.load_data()\n",
        "#normnalize in and pad\n",
        "mnist_x_train = np.pad(mnist_x_train,((0,0),(2,2),(2,2)))/255.\n",
        "print(np.shape(mnist_x_train))\n",
        "mnist_x_test = np.pad(mnist_x_test,((0,0),(2,2),(2,2)))/255.\n",
        "fashion_mnist_x_train = np.pad(fashion_mnist_x_train,((0,0),(2,2),(2,2)))/255.\n",
        "fashion_mnist_x_test = np.pad(fashion_mnist_x_test,((0,0),(2,2),(2,2)))/255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBMEeCUCUlDb",
        "outputId": "7434f5be-44ad-4eb0-8bb5-b4fdd3acbf20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 32, 32)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(mnist_x_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Datagenerator"
      ],
      "metadata": {
        "id": "o9mPZ94mluoa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa7WArmbUnff"
      },
      "outputs": [],
      "source": [
        "def datagenerator(x1,x2,batchsize):\n",
        "    n1 = x1.shape[0]\n",
        "    n2 = x2.shape[0]\n",
        "    while True:\n",
        "        num1 = np.random.randint(0, n1, batchsize)\n",
        "        num2 = np.random.randint(0, n2, batchsize)\n",
        "\n",
        "        x_data = (x1[num1] + x2[num2]) / 2.0\n",
        "        y_data = np.concatenate((x1[num1], x2[num2]), axis=2)\n",
        "\n",
        "        yield x_data, y_data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziF7vZMxUp32"
      },
      "outputs": [],
      "source": [
        "batch_sz = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Training and Testing datagenerator"
      ],
      "metadata": {
        "id": "Hb2m53mVlx7n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WEv6kbHUuQV"
      },
      "outputs": [],
      "source": [
        "train_generator = datagenerator(mnist_x_train,fashion_mnist_x_train,batch_sz)\n",
        "test_generator = datagenerator(mnist_x_test,fashion_mnist_x_test,batch_sz)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Model"
      ],
      "metadata": {
        "id": "E_eAXiIGlX85"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfSS1WakVCp9"
      },
      "source": [
        "## Internal Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADtGSR5zVEbF"
      },
      "outputs": [],
      "source": [
        "#Conv block consists of a convolution layer with ReLU\n",
        "def conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
        "  \n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(x)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(conv)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    \n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "\n",
        "    return conv\n",
        "    \n",
        "\n",
        "# lambda function to repeat Repeats the elements of a tensor along an axis by a factor of rep.\n",
        "def repeat_elem(tensor, rep):\n",
        "     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n",
        "                          arguments={'repnum': rep})(tensor)\n",
        "\n",
        "\n",
        "#Residual convolutional layer.\n",
        "def res_conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
        " \n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation('relu')(conv)\n",
        "    \n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "\n",
        "    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n",
        "\n",
        "    res_path = layers.add([shortcut, conv])\n",
        "    #Activation after addition with shortcut\n",
        "    res_path = layers.Activation('relu')(res_path)    \n",
        "    return res_path\n",
        "\n",
        "\n",
        "#resize the down layer feature map into the same dimension as the up layer feature map using 1x1 conv\n",
        "def gating_signal(input, out_size, batch_norm=False):\n",
        "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
        "    if batch_norm:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def attention_block(x, gating, inter_shape):\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "\n",
        "    #x signal to the same shape as the gating signal\n",
        "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "    #gating signal to the same number of filters as the inter_shape\n",
        "    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)\n",
        "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),\n",
        "                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n",
        "                                 padding='same')(phi_g)  # 16\n",
        "\n",
        "    concat_xg = layers.add([upsample_g, theta_x])\n",
        "    act_xg = layers.Activation('relu')(concat_xg)\n",
        "    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
        "\n",
        "    upsample_psi = repeat_elem(upsample_psi, shape_x[3])\n",
        "\n",
        "    y = layers.multiply([upsample_psi, x])\n",
        "\n",
        "    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n",
        "    result_bn = layers.BatchNormalization()(result)\n",
        "    return result_bn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESAnl535EWcR"
      },
      "source": [
        "Build the model method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFO74gOVEQy_"
      },
      "outputs": [],
      "source": [
        "#Rsidual UNet, with attention \n",
        "def a_ResUNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True, FILTER_NUM= 64):# number of basic filters for the first layer\n",
        "    \n",
        "    # network structure\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "    # input data\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "    axis = 3\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, double residual convolution + pooling\n",
        "    conv_128 = res_conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
        "    # DownRes 2\n",
        "    conv_64 = res_conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
        "    # DownRes 3\n",
        "    conv_32 = res_conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
        "    # DownRes 4\n",
        "    conv_16 = res_conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n",
        "    # DownRes 5, convolution only\n",
        "    conv_8 = res_conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "\n",
        "    # Upsampling layers\n",
        "    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n",
        "    gating_16 = gating_signal(conv_8, 8*FILTER_NUM, batch_norm)\n",
        "    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)\n",
        "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
        "    up_16 = layers.concatenate([up_16, att_16], axis=axis)\n",
        "    up_conv_16 = res_conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 7\n",
        "    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n",
        "    gating_32 = gating_signal(conv_16, 8*FILTER_NUM, batch_norm)\n",
        "    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)\n",
        "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_16)\n",
        "    up_32 = layers.concatenate([up_32, att_32], axis=axis)\n",
        "    up_conv_32 = res_conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 8\n",
        "    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
        "    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)\n",
        "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, att_64], axis=axis)\n",
        "    up_conv_64 = res_conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 9\n",
        "    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
        "    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)\n",
        "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = layers.concatenate([up_128, att_128], axis=axis)\n",
        "    up_conv_128 = res_conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # 1*1 convolutional layers\n",
        "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
        "    conv_final = layers.BatchNormalization(axis=axis)(conv_final)\n",
        "    conv_final = layers.Activation('sigmoid')(conv_final)\n",
        "    conv_difference = 2*inputs - conv_final\n",
        "    conv_concat = layers.concatenate([conv_difference, conv_final], axis = 2)\n",
        "\n",
        "    # Model integration\n",
        "    model = models.Model(inputs, conv_concat, name=\"a_RsUNet\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVJhu-KnE9YY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9bacdb-4ad5-49d6-9283-255abb35dd89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"a_RsUNet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 32, 64)   640         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 32, 32, 64)  256         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 32, 32, 64)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 64)   128         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 64)   36928       ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 32, 32, 64)   0           ['batch_normalization_2[0][0]',  \n",
            "                                                                  'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 32, 32, 64)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 16, 16, 64)   0           ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 16, 16, 128)  73856       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 16, 16, 128)  0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 128)  8320        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 16, 16, 128)  147584      ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 16, 16, 128)  0           ['batch_normalization_5[0][0]',  \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 16, 16, 128)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 128)   0           ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 8, 8, 256)    295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 8, 8, 256)    0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 8, 8, 256)    33024       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 8, 8, 256)    590080      ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 8, 8, 256)    0           ['batch_normalization_8[0][0]',  \n",
            "                                                                  'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 8, 8, 256)    0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 256)   0           ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 4, 4, 512)    1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 4, 4, 512)   2048        ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 4, 4, 512)    0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 4, 4, 512)    131584      ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 4, 4, 512)    2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 4, 4, 512)    0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 4, 4, 512)    262656      ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 4, 4, 512)    0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 4, 4, 256)    131328      ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 4, 4, 256)   590080      ['conv2d_26[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 4, 4, 256)    0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 4, 4, 256)    0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 4, 4, 1)      257         ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 4, 4, 1)      0           ['conv2d_27[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 1)     0           ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 8, 8, 256)    0           ['up_sampling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 8, 8, 256)    0           ['lambda_1[0][0]',               \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 8, 8, 256)    65792       ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 512)   0           ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['up_sampling2d_3[0][0]',        \n",
            "                                                                  'batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 8, 8, 256)    1769728     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 8, 8, 256)    196864      ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 8, 8, 256)    590080      ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 8, 8, 256)    0           ['batch_normalization_25[0][0]', \n",
            "                                                                  'batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 8, 8, 256)    0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 8, 8, 128)    32896       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 8, 8, 128)   512         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 8, 8, 128)    16512       ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 8, 8, 128)   147584      ['conv2d_34[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 8, 8, 128)    0           ['conv2d_transpose_2[0][0]',     \n",
            "                                                                  'conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 8, 8, 128)    0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 8, 8, 1)      129         ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 8, 8, 1)      0           ['conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 1)   0           ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 16, 16, 128)  0           ['up_sampling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 16, 16, 128)  0           ['lambda_2[0][0]',               \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 16, 16, 128)  16512       ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 16, 16, 256)  0          ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 128)  512        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 16, 16, 384)  0           ['up_sampling2d_5[0][0]',        \n",
            "                                                                  'batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 16, 16, 128)  442496      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 128)  512        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 16, 16, 128)  49280       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 16, 16, 128)  147584      ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 16, 16, 128)  512        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 16, 16, 128)  512        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 16, 16, 128)  0           ['batch_normalization_30[0][0]', \n",
            "                                                                  'batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 128)  0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 16, 16, 64)   8256        ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 16, 16, 64)  256         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 16, 16, 64)   4160        ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 16, 16, 64)  36928       ['conv2d_42[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 16, 16, 64)   16448       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 16, 16, 64)   0           ['conv2d_transpose_3[0][0]',     \n",
            "                                                                  'conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 64)   0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 16, 16, 1)    65          ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 16, 16, 1)    0           ['conv2d_43[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSampling2D)  (None, 32, 32, 1)   0           ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 32, 32, 64)   0           ['up_sampling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 32, 32, 64)   0           ['lambda_3[0][0]',               \n",
            "                                                                  'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 32, 32, 64)   4160        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_7 (UpSampling2D)  (None, 32, 32, 128)  0          ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 32, 32, 64)  256         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 32, 32, 192)  0           ['up_sampling2d_7[0][0]',        \n",
            "                                                                  'batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 32, 32, 64)   110656      ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 32, 32, 64)  256         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 32, 32, 64)   12352       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 32, 32, 64)   36928       ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 32, 32, 64)  256         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 32, 32, 64)  256         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 32, 32, 64)   0           ['batch_normalization_35[0][0]', \n",
            "                                                                  'batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 32, 32, 64)   0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 32, 32, 1)    65          ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 32, 32, 1)   4           ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None, 32, 32, 1)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 32, 32, 1)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLambda)  (None, 32, 32, 1)    0           ['tf.math.multiply[0][0]',       \n",
            "                                                                  'activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 32, 64, 1)    0           ['tf.math.subtract[0][0]',       \n",
            "                                                                  'activation_31[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,896,648\n",
            "Trainable params: 9,885,894\n",
            "Non-trainable params: 10,754\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_shape = (32,32,1)\n",
        "a_RsUNet_model = a_ResUNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True)\n",
        "a_RsUNet_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Attention Res UNet.\n",
        "Adam as optimizer and set as metrics the mse.\n",
        "Print the summary of the model"
      ],
      "metadata": {
        "id": "lome4Pnpk4zI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8kZvgJwFPK6"
      },
      "outputs": [],
      "source": [
        "callback_checkpoint = ModelCheckpoint('a_RsUNet_model.{epoch:02d}-{val_loss:.6f}.hdf5', save_weights_only=True) \n",
        "#Configures the model for training with optimizer Adam and as Loss function Mean Squared error\n",
        "a_RsUNet_model.compile(optimizer=Adam(), loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings parameters"
      ],
      "metadata": {
        "id": "eVNC0vdMmKqu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do_MPnrVFPK7"
      },
      "outputs": [],
      "source": [
        "N_train, w, h = mnist_x_train.shape[0], mnist_x_train.shape[1], mnist_x_train.shape[2]\n",
        "N_test = mnist_x_test.shape[0] \n",
        "stpepoch = 10000 #steps per epochs,increasing it to avoid overfitting\n",
        "vlsteps = N_test // batch_sz #validation steps"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trains the model for a fixed number of epochs.\n",
        "The history object returned by the fit method of model."
      ],
      "metadata": {
        "id": "bSRw9agUmO3S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHylvYQ7FPK9",
        "outputId": "579e82c8-5113-4465-e7ca-6a2605ac1273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 621s 58ms/step - loss: 6.2795e-04 - val_loss: 5.7874e-04\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 581s 58ms/step - loss: 5.2334e-04 - val_loss: 4.9547e-04\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 581s 58ms/step - loss: 4.7242e-04 - val_loss: 4.4219e-04\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 580s 58ms/step - loss: 4.4436e-04 - val_loss: 4.5993e-04\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 580s 58ms/step - loss: 4.2452e-04 - val_loss: 4.2917e-04\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 580s 58ms/step - loss: 4.0845e-04 - val_loss: 4.3379e-04\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 580s 58ms/step - loss: 3.9827e-04 - val_loss: 4.0001e-04\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 581s 58ms/step - loss: 3.8660e-04 - val_loss: 3.9357e-04\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 580s 58ms/step - loss: 3.7867e-04 - val_loss: 3.8451e-04\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 582s 58ms/step - loss: 3.7278e-04 - val_loss: 3.8051e-04\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 588s 59ms/step - loss: 3.6775e-04 - val_loss: 3.8193e-04\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 588s 59ms/step - loss: 3.6122e-04 - val_loss: 3.6628e-04\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 588s 59ms/step - loss: 3.5500e-04 - val_loss: 3.6328e-04\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 588s 59ms/step - loss: 3.5023e-04 - val_loss: 3.5941e-04\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 588s 59ms/step - loss: 3.4684e-04 - val_loss: 3.6429e-04\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 588s 59ms/step - loss: 3.4270e-04 - val_loss: 3.5677e-04\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 589s 59ms/step - loss: 3.3937e-04 - val_loss: 3.5253e-04\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 591s 59ms/step - loss: 3.3775e-04 - val_loss: 3.4776e-04\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 589s 59ms/step - loss: 3.3665e-04 - val_loss: 3.5066e-04\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 588s 59ms/step - loss: 3.3410e-04 - val_loss: 3.5610e-04\n"
          ]
        }
      ],
      "source": [
        "hst = a_RsUNet_model.fit(train_generator,\n",
        "                                   epochs=20,\n",
        "                                   batch_size=batch_sz,\n",
        "                                   validation_data=test_generator,\n",
        "                                   callbacks=[callback_checkpoint],\n",
        "                                   steps_per_epoch=stpepoch,\n",
        "                                   validation_steps=vlsteps)#Data on which to evaluate the loss and any model metrics at the end of each epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVeGRAzOKN6o"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to predict the first image in the test set and then show it compared with the original in the x_test set and the expected solution in the y_test set."
      ],
      "metadata": {
        "id": "bHLMp2Kymoh4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K7QjqT1KTTi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "1a520782-9d97-4fb1-cbee-f5b53e7c3feb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x_batch, y_batch = next(test_generator)\n",
        "x = x_batch[0]\n",
        "y = y_batch[0]\n",
        "y_pred = a_RsUNet_model.predict(x.reshape((1,32,32)))\n",
        "fig, axs = plt.subplots(1, 3, gridspec_kw={'width_ratios': (1,2,2)}, figsize=(20, 6))\n",
        "axs[0].imshow(x, cmap='gray', interpolation='nearest')\n",
        "axs[1].imshow(y, cmap='gray', interpolation='nearest')\n",
        "axs[2].imshow(y_pred[0].reshape((32,64)), cmap='gray', interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat computation 10 times and check the Standard deviation (std)"
      ],
      "metadata": {
        "id": "jjIJp6iToxxA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EJQCgZx8mfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827569b9-a788-4e7c-cad1-dfab4a37f26e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 8s 12ms/step - loss: 3.5588e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.5715e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.5012e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.5719e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.5245e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.5434e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.5209e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.5573e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.4897e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.5510e-04\n",
            "[0.0003558833268471062, 0.0003571545530576259, 0.000350118731148541, 0.00035718828439712524, 0.00035244569880887866, 0.0003543404454831034, 0.00035208891495130956, 0.00035573181230574846, 0.00034897419391199946, 0.00035509883309714496]\n",
            "Min: 0.00034897419391199946\n",
            "Mean: 0.00035390247940085827\n",
            "Std: 2.7254681044366996e-06\n"
          ]
        }
      ],
      "source": [
        "#Evaluate the mse over 20000 samples randomly generated from the two test_sets\n",
        "test_generator = datagenerator(mnist_x_test, fashion_mnist_x_test, 20000)\n",
        "vect_mse = []#array of mse scores\n",
        "for i in range(10):#for loop of 10 iterations to compute the mse in a vector\n",
        "  x_batch, y_batch = next(test_generator)\n",
        "  mse = a_RsUNet_model.evaluate(x_batch, y_batch)\n",
        "  vect_mse.append(mse)\n",
        "print(vect_mse)\n",
        "print('Min:', min(vect_mse))#minimum of mse values\n",
        "print('Mean:', np.mean(vect_mse))#mean of mse values in vector\n",
        "print('Std:', np.std(vect_mse))#standard deviation of mse"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "The problem is solved considering it as a Segmentaion problem,for which given an image x, classify each pixel of x into one possible class.\n",
        "It's an Image-to-image maps that are usually implemented as variant of a Fully Convolutional Neural Network design.\n",
        "Try to use UNet, a convolutional neural network based on the fully convolutional network.\n",
        "It's a U-shaped structure with  contracting path and expansive path.\n",
        "Contracting path is a typical convolutional network that consists of repeated application of convolutions, each followed by ReLU and a max pooling operation.\n",
        "Expansive pathway combines the feature and spatial information through a sequence of up-convolutions and concatenations with high-resolution features from the opposite path.\n",
        "\n",
        "\n",
        "\n",
        "Residual neural network (ResNet) is an artificial neural network. It is a gateless or open-gated NN working very deep feedforward neural network with hundreds of layers.\n",
        "ResNet models are implemented with double- or triple- layer skips that contain nonlinearities (ReLU) and batch normalization in between.\n",
        "\n",
        "Attention Mechanism can be implemented as gating functions.\n",
        "The gating maps are dynamically generated by some NN allowing to focus on di\u000bfferent part on the input at diff\u000berent times.\n",
        "Attention layers are only in expansive pathway and takes 2 inputs.\n",
        "An input is the gating signal from next lowest layer and due to the fact it comes from deeper part of NN it has a better feature representation. The second input is x that comes from early layers and has bettere spatial information. "
      ],
      "metadata": {
        "id": "RHGzp2rlkfJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second model\n",
        "First model with some variations:\n",
        "model with reduced numbers of layers;\n",
        "epochs increased to 30 in fit method;\n",
        "method that change automatically the learning rate using ReduceLROnPlateau class."
      ],
      "metadata": {
        "id": "do6Ym5J3V2FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rsidual UNet with attention\n",
        "\n",
        "def A_ResUNet_simple(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True, FILTER_NUM= 64):\n",
        "    # network structure\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "    # input data\n",
        "    # dimension of the image depth\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "    axis = 3\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, double residual convolution + pooling\n",
        "    conv_128 = res_conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
        "    # DownRes 2\n",
        "    conv_64 = res_conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
        "    # DownRes 3\n",
        "    conv_32 = res_conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
        "    # DownRes 4\n",
        "    conv_16 = res_conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    gating_32 = gating_signal(conv_16, 8*FILTER_NUM, batch_norm)\n",
        "    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)\n",
        "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_16)\n",
        "    up_32 = layers.concatenate([up_32, att_32], axis=axis)\n",
        "    up_conv_32 = res_conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 8\n",
        "    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
        "    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)\n",
        "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, att_64], axis=axis)\n",
        "    up_conv_64 = res_conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 9\n",
        "    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
        "    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)\n",
        "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = layers.concatenate([up_128, att_128], axis=axis)\n",
        "    up_conv_128 = res_conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # 1*1 convolutional layers\n",
        "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
        "    conv_final = layers.BatchNormalization(axis=axis)(conv_final)\n",
        "    conv_final = layers.Activation('sigmoid')(conv_final)\n",
        "    conv_difference = 2*inputs - conv_final\n",
        "    conv_concat = layers.concatenate([conv_difference, conv_final], axis = 2)\n",
        "\n",
        "\n",
        "    # Model integration\n",
        "    model = models.Model(inputs, conv_concat, name=\"A_ResUNet_simple\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "PZqpWLpkV5Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (32,32,1)\n",
        "a_ResUNet_model_smp = A_ResUNet_simple(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True)\n",
        "a_ResUNet_model_smp.summary()\n",
        "callback_checkpoint = ModelCheckpoint('a_ResUNet_model_smp.{epoch:02d}-{val_loss:.6f}.hdf5', save_weights_only=True) \n",
        "\n",
        "#ReduceLROnPlateau: reduce learning rate when a metric has stopped improving by a factor of 2-10 once learning stagnates\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor = 0.1,patience = 2,min_delta = 1e-5, min_lr = 1e-6)\n",
        "a_ResUNet_model_smp.compile(optimizer=Adam(), loss='mse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbiNo5x9YtT6",
        "outputId": "cb4a641d-109c-4670-be78-23cfd8196b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"A_ResUNet_simple\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 32, 64)   640         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 32, 32, 64)  256         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 32, 32, 64)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 64)   128         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 64)   36928       ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 32, 32, 64)   0           ['batch_normalization_2[0][0]',  \n",
            "                                                                  'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 32, 32, 64)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 16, 16, 64)   0           ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 16, 16, 128)  73856       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 16, 16, 128)  0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 128)  8320        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 16, 16, 128)  147584      ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 16, 16, 128)  0           ['batch_normalization_5[0][0]',  \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 16, 16, 128)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 128)   0           ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 8, 8, 256)    295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 8, 8, 256)    0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 8, 8, 256)    33024       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 8, 8, 256)    590080      ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 8, 8, 256)    0           ['batch_normalization_8[0][0]',  \n",
            "                                                                  'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 8, 8, 256)    0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 256)   0           ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 4, 4, 512)    1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 4, 4, 512)   2048        ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 4, 4, 512)    0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 4, 4, 512)    131584      ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 4, 4, 512)    2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 4, 4, 512)    0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 4, 4, 512)    262656      ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 4, 4, 512)    0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 4, 4, 256)    131328      ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 4, 4, 256)   590080      ['conv2d_14[0][0]']              \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 4, 4, 256)    0           ['conv2d_transpose[0][0]',       \n",
            "                                                                  'conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 4, 4, 256)    0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 4, 4, 1)      257         ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 4, 4, 1)      0           ['conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 8, 8, 1)      0           ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 8, 8, 256)    0           ['up_sampling2d[0][0]']          \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 8, 8, 256)    0           ['lambda[0][0]',                 \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 8, 8, 256)    65792       ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 8, 8, 512)   0           ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['up_sampling2d_1[0][0]',        \n",
            "                                                                  'batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 8, 8, 256)    1769728     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 8, 8, 256)    196864      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 8, 8, 256)    590080      ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 8, 8, 256)    0           ['batch_normalization_16[0][0]', \n",
            "                                                                  'batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 8, 8, 256)    0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 8, 8, 128)    32896       ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 8, 8, 128)   512         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 8, 8, 128)    16512       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 8, 8, 128)   147584      ['conv2d_22[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 8, 8, 128)    0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 8, 8, 128)    0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 8, 8, 1)      129         ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 8, 8, 1)      0           ['conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 16, 16, 1)   0           ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 16, 16, 128)  0           ['up_sampling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 16, 16, 128)  0           ['lambda_1[0][0]',               \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 128)  16512       ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 256)  0          ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 128)  512        ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 16, 16, 384)  0           ['up_sampling2d_3[0][0]',        \n",
            "                                                                  'batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 128)  442496      ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 128)  512        ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 128)  49280       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 16, 16, 128)  147584      ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 128)  512        ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 128)  512        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 16, 16, 128)  0           ['batch_normalization_21[0][0]', \n",
            "                                                                  'batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 128)  0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 64)   8256        ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 64)  256         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 16, 16, 64)   4160        ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 16, 16, 64)  36928       ['conv2d_30[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 16, 16, 64)   16448       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 16, 16, 64)   0           ['conv2d_transpose_2[0][0]',     \n",
            "                                                                  'conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 64)   0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 16, 16, 1)    65          ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 1)    0           ['conv2d_31[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 1)   0           ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 32, 32, 64)   0           ['up_sampling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 32, 32, 64)   0           ['lambda_2[0][0]',               \n",
            "                                                                  'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 32, 32, 64)   4160        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 128)  0          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 32, 32, 64)  256         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 32, 32, 192)  0           ['up_sampling2d_5[0][0]',        \n",
            "                                                                  'batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 32, 32, 64)   110656      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 32, 32, 64)  256         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 32, 32, 64)   12352       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 32, 32, 64)   36928       ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 32, 32, 64)  256         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 32, 32, 64)  256         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 32, 32, 64)   0           ['batch_normalization_26[0][0]', \n",
            "                                                                  'batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 32, 32, 64)   0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 32, 32, 1)    65          ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 32, 32, 1)   4           ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None, 32, 32, 1)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 32, 32, 1)    0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLambda)  (None, 32, 32, 1)    0           ['tf.math.multiply[0][0]',       \n",
            "                                                                  'activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 32, 64, 1)    0           ['tf.math.subtract[0][0]',       \n",
            "                                                                  'activation_23[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,896,648\n",
            "Trainable params: 9,885,894\n",
            "Non-trainable params: 10,754\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_train, w, h = mnist_x_train.shape[0], mnist_x_train.shape[1], mnist_x_train.shape[2]\n",
        "N_test = mnist_x_test.shape[0]\n",
        "\n",
        "steps_per_epoch = 10000 #increasing the steps_per_epoch to avoid overfitting\n",
        "val_steps = N_test // batch_sz\n",
        "\n",
        "hist = a_ResUNet_model_smp.fit(train_generator,\n",
        "                                   epochs=30,#30 epochs\n",
        "                                   batch_size=batch_sz,\n",
        "                                   validation_data=test_generator,\n",
        "                                   callbacks=[callback_checkpoint,reduce_lr],\n",
        "                                   steps_per_epoch=steps_per_epoch,\n",
        "                                   validation_steps=val_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hkBvW7JY5ws",
        "outputId": "b3ebb863-7b87-4335-ddb7-6af0c9cdb5cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "10000/10000 [==============================] - 607s 59ms/step - loss: 0.0067 - val_loss: 7.9868e-04 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "10000/10000 [==============================] - 593s 59ms/step - loss: 6.5960e-04 - val_loss: 6.2894e-04 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "10000/10000 [==============================] - 592s 59ms/step - loss: 5.3219e-04 - val_loss: 4.8646e-04 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "10000/10000 [==============================] - 594s 59ms/step - loss: 4.7871e-04 - val_loss: 4.6012e-04 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "10000/10000 [==============================] - 596s 60ms/step - loss: 4.4614e-04 - val_loss: 4.4123e-04 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "10000/10000 [==============================] - 592s 59ms/step - loss: 4.2589e-04 - val_loss: 4.6457e-04 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "10000/10000 [==============================] - 589s 59ms/step - loss: 4.1124e-04 - val_loss: 4.1829e-04 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "10000/10000 [==============================] - 591s 59ms/step - loss: 3.9772e-04 - val_loss: 4.2355e-04 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "10000/10000 [==============================] - 591s 59ms/step - loss: 3.8761e-04 - val_loss: 4.8016e-04 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "10000/10000 [==============================] - 589s 59ms/step - loss: 3.5724e-04 - val_loss: 3.5632e-04 - lr: 1.0000e-04\n",
            "Epoch 11/30\n",
            "10000/10000 [==============================] - 589s 59ms/step - loss: 3.5024e-04 - val_loss: 3.5386e-04 - lr: 1.0000e-04\n",
            "Epoch 12/30\n",
            "10000/10000 [==============================] - 589s 59ms/step - loss: 3.4734e-04 - val_loss: 3.4728e-04 - lr: 1.0000e-04\n",
            "Epoch 13/30\n",
            "10000/10000 [==============================] - 592s 59ms/step - loss: 3.4359e-04 - val_loss: 3.4903e-04 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "10000/10000 [==============================] - 589s 59ms/step - loss: 3.4291e-04 - val_loss: 3.4421e-04 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "10000/10000 [==============================] - 593s 59ms/step - loss: 3.4289e-04 - val_loss: 3.4693e-04 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "10000/10000 [==============================] - 590s 59ms/step - loss: 3.4234e-04 - val_loss: 3.4132e-04 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "10000/10000 [==============================] - 591s 59ms/step - loss: 3.4162e-04 - val_loss: 3.5164e-04 - lr: 1.0000e-06\n",
            "Epoch 18/30\n",
            "10000/10000 [==============================] - 593s 59ms/step - loss: 3.4192e-04 - val_loss: 3.4666e-04 - lr: 1.0000e-06\n",
            "Epoch 19/30\n",
            "10000/10000 [==============================] - 592s 59ms/step - loss: 3.4150e-04 - val_loss: 3.4145e-04 - lr: 1.0000e-06\n",
            "Epoch 20/30\n",
            "10000/10000 [==============================] - 594s 59ms/step - loss: 3.4291e-04 - val_loss: 3.5441e-04 - lr: 1.0000e-06\n",
            "Epoch 21/30\n",
            "10000/10000 [==============================] - 588s 59ms/step - loss: 3.4276e-04 - val_loss: 3.5106e-04 - lr: 1.0000e-06\n",
            "Epoch 22/30\n",
            "10000/10000 [==============================] - 587s 59ms/step - loss: 3.4230e-04 - val_loss: 3.3921e-04 - lr: 1.0000e-06\n",
            "Epoch 23/30\n",
            "10000/10000 [==============================] - 585s 59ms/step - loss: 3.4203e-04 - val_loss: 3.4850e-04 - lr: 1.0000e-06\n",
            "Epoch 24/30\n",
            "10000/10000 [==============================] - 586s 59ms/step - loss: 3.4183e-04 - val_loss: 3.4837e-04 - lr: 1.0000e-06\n",
            "Epoch 25/30\n",
            "10000/10000 [==============================] - 587s 59ms/step - loss: 3.4178e-04 - val_loss: 3.4548e-04 - lr: 1.0000e-06\n",
            "Epoch 26/30\n",
            "10000/10000 [==============================] - 586s 59ms/step - loss: 3.4258e-04 - val_loss: 3.4970e-04 - lr: 1.0000e-06\n",
            "Epoch 27/30\n",
            "10000/10000 [==============================] - 583s 58ms/step - loss: 3.4210e-04 - val_loss: 3.4852e-04 - lr: 1.0000e-06\n",
            "Epoch 28/30\n",
            "10000/10000 [==============================] - 581s 58ms/step - loss: 3.4103e-04 - val_loss: 3.4439e-04 - lr: 1.0000e-06\n",
            "Epoch 29/30\n",
            "10000/10000 [==============================] - 582s 58ms/step - loss: 3.4159e-04 - val_loss: 3.4496e-04 - lr: 1.0000e-06\n",
            "Epoch 30/30\n",
            "10000/10000 [==============================] - 586s 59ms/step - loss: 3.4182e-04 - val_loss: 3.4412e-04 - lr: 1.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test\n",
        "Repeat computation 10 times and check the Standard deviation (std)"
      ],
      "metadata": {
        "id": "gXXshOv-Xaa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the mse over 20000 samples randomly generated from the two test_sets.\n",
        "test_gn_2 = datagenerator(mnist_x_test, fashion_mnist_x_test, 20000)\n",
        "vect_mse = []#array of mse scores\n",
        "for i in range(10):#for loop of 10 iterations to compute the mse in a vector\n",
        "  x_batch, y_batch = next(test_gn_2)\n",
        "  mse = a_ResUNet_model_smp.evaluate(x_batch, y_batch)\n",
        "  vect_mse.append(mse)\n",
        "print(vect_mse)\n",
        "print('Min:', min(vect_mse))#minimum of mse values\n",
        "print('Mean:', np.mean(vect_mse))#mean of mse values in vector\n",
        "print('Std:', np.std(vect_mse))#standard deviation of mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHvqKiMRXQD9",
        "outputId": "2f6ffe27-7e7a-4ff3-f5a2-425976599682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 8s 12ms/step - loss: 3.4911e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.4475e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.4960e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.4760e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.4328e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.4790e-04\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 3.4925e-04\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 3.4739e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.4990e-04\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 3.4608e-04\n",
            "[0.00034910719841718674, 0.00034474977292120457, 0.0003495975979603827, 0.0003475983685348183, 0.000343283754773438, 0.00034790203790180385, 0.0003492514370009303, 0.0003473859396763146, 0.00034989710547961295, 0.00034607871202751994]\n",
            "Min: 0.000343283754773438\n",
            "Mean: 0.0003474851924693212\n",
            "Std: 2.081809560726218e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second model has a smallest std value on 20000 samples of text_sets around 2.08 e-06\n",
        "while the first model has std around 2.72 e-06.\n",
        "\n",
        "Validation loss.\n",
        "model 1 val_loss: 3.5610e-04 at epoch 20; \n",
        "model 2 val_loss: 3.4412e-04 at epoch 30.\n",
        "\n"
      ],
      "metadata": {
        "id": "82M8cZplSU5d"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Martina_Ianaro.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}